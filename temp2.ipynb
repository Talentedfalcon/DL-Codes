{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 15:57:36.408243: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741535859.120609    9297 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741535859.749239    9297 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-09 15:57:47.067928: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist=tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, _), (test_images, _)=fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mVAE\u001b[39;00m(\u001b[43mtf\u001b[49m.keras.Model):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,latent_dim):\n\u001b[32m      3\u001b[39m         \u001b[38;5;28msuper\u001b[39m(VAE,\u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self,latent_dim):\n",
    "        super(VAE,self).__init__()\n",
    "        self.latent_dim=latent_dim\n",
    "        self.encoder=tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(28,28,1)),\n",
    "                tf.keras.layers.Conv2D(filters=32,kernel_size=3,strides=(2,2),activation='relu'),\n",
    "                tf.keras.layers.Conv2D(filters=64,kernel_size=3,strides=(2,2),activation='relu'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(latent_dim+latent_dim)\n",
    "            ]\n",
    "        )\n",
    "        self.decoder=tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "                tf.keras.layers.Dense(units=7*7*32,activation='relu'),\n",
    "                tf.keras.layers.Reshape(target_shape=(7,7,32)),\n",
    "                tf.keras.layers.Conv2DTranspose(filters=64,kernel_size=3,strides=2,padding='same',activation='relu'),\n",
    "                tf.keras.layers.Conv2DTranspose(filters=32,kernel_size=3,strides=2,padding='same',activation='relu'),\n",
    "                tf.keras.layers.Conv2DTranspose(filters=1,kernel_size=3,strides=1,padding='same')\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def encode(self,x):\n",
    "        mean,logvar=tf.split(self.encoder(x),num_or_size_splits=2,axis=1)\n",
    "        return mean,logvar\n",
    "    \n",
    "    def reparameterize(self,mean,logvar):\n",
    "        epsilon=tf.random.normal(shape=mean.shape)\n",
    "        return epsilon*tf.exp(logvar*0.5)+mean\n",
    "    \n",
    "    def sampling(self,mean,logvar):\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(tf.shape(mean)[0], self.latent_dim), mean=0.0, stddev=1.0)\n",
    "        return mean + tf.keras.backend.exp(0.5 * logvar) * epsilon\n",
    "\n",
    "    def decode(self,z):\n",
    "        logits=self.decoder(z)\n",
    "        return logits\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        x=self.encoder(inputs)\n",
    "        mean,logvar=self.encode(x)\n",
    "        z=self.reparameterize(mean,logvar)\n",
    "        reconstructed=self.decoder(z)\n",
    "        return reconstructed,mean,logvar\n",
    "    \n",
    "    def compute_loss(self,x_og,x_recon,mean,logvar):\n",
    "        recon_loss=tf.keras.losses.binary_crossentropy(tf.keras.backend.flatten(x_og),tf.keras.backend.flatten(x_recon))\n",
    "        recon_loss=tf.keras.backend.sum(recon_loss)\n",
    "\n",
    "        kl_loss=-0.5*tf.keras.backend.sum(1+logvar-tf.keras.backend.square(mean)-tf.keras.backend.exp(logvar),axis=-1)\n",
    "\n",
    "        return tf.keras.backend.mean(recon_loss+kl_loss)\n",
    "    \n",
    "    def train_step(self,data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred,mean,logvar=self(data)\n",
    "            loss=self.compute_loss(data,y_pred,mean,logvar)\n",
    "\n",
    "        gradients=tape.gradient(loss,self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients,self.trainable_variables))\n",
    "\n",
    "        return {\"loss\":loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae=VAE(latent_dim=16)\n",
    "vae.compile(optimizers=\"adam\")\n",
    "vae.fit(train_images,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
